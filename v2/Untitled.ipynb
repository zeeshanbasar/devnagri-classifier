{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler, EarlyStopping\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "import time\n",
    "\n",
    "#model name\n",
    "NAME=\"devnagri-{}\".format(int(time.time()))\n",
    "\n",
    "# TensorBoard\n",
    "tensorboard=TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "# GPU\n",
    "gpu_options=tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "\n",
    "# load the directory where image(or dataset) folders are\n",
    "DATADIR='C:\\IDK\\ML\\Devnagri\\DevanagariHandwrittenCharacterDataset\\Train'\n",
    "CATEGORIES=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\n",
    "           \"adna\",\"ba\",\"bha\",\"cha\",\"chha\",\"chhya\",\"da\",\"daa\",\"dha\",\"dhaa\",\"ga\",\n",
    "           \"gha\",\"gya\",\"ha\",\"ja\",\"jha\",\"ka\",\"kha\",\"kna\",\"ksha\",\"la\",\"ma\",\"na\",\n",
    "           \"pa\",\"pha\",\"ra\",\"sa\",\"sh\",\"t\",\"ta\",\"tha\",\"thaa\",\"tra\",\"waw\",\"yaw\",\"yna\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# creating the training data from the images dataset\n",
    "\n",
    "random.seed(1)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=random.random()*180,\n",
    "    width_shift_range=[-5*random.random(),10*random.random()],\n",
    "    height_shift_range=[-10*random.random(),5*random.random()],\n",
    "    shear_range=10*random.random(),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    channel_shift_range=random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path=os.path.join(DATADIR,category)\n",
    "        class_num=CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):            \n",
    "            img_array=cv2.imread(os.path.join(path,img))\n",
    "            new_array=cv2.resize(img_array,(32,32))\n",
    "            image = img_to_array(new_array)\n",
    "            image = preprocess_input(image)\n",
    "            image = train_datagen.random_transform(image)\n",
    "            image=np.array(image)#.reshape((-1, 32, 32, 3))            \n",
    "            training_data.append([image,class_num])\n",
    "create_training_data()\n",
    "\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for features, labels in training_data:\n",
    "    X.append(features)\n",
    "    y.append(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X).reshape((-1, 32, 32, 3))\n",
    "y=np.array(y)\n",
    "y=tf.keras.utils.to_categorical(y, num_classes=46, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78200, 32, 32, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78200, 46)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save X,y as proper training data\n",
    "pickle_out=open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out=open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the model\n",
    "model=Sequential()\n",
    "# layer 1\n",
    "model.add(tfl.Conv2D(64,(3,3)))\n",
    "model.add(tfl.Activation('relu'))\n",
    "model.add(tfl.MaxPooling2D(pool_size=(2,2)))\n",
    "#layer 2\n",
    "model.add(tfl.Conv2D(64,(3,3)))\n",
    "model.add(tfl.Activation('relu'))\n",
    "model.add(tfl.MaxPooling2D(pool_size=(2,2)))\n",
    "#layer 3\n",
    "model.add(tfl.Conv2D(64,(3,3)))\n",
    "model.add(tfl.Activation('relu'))\n",
    "model.add(tfl.MaxPooling2D(pool_size=(2,2)))\n",
    "# Dense 1\n",
    "model.add(tfl.Flatten())\n",
    "model.add(tfl.Dense(64))\n",
    "model.add(tfl.Activation('relu'))\n",
    "# Dense 2\n",
    "model.add(tfl.Flatten())\n",
    "model.add(tfl.Dense(64))\n",
    "model.add(tfl.Activation('relu'))\n",
    "# o/p layer\n",
    "model.add(tfl.Dense(46))        # 1 for binary class\n",
    "model.add(tfl.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation, loss, accuracy, optimizer\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "             optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy','AUC'])\n",
    "\n",
    "\n",
    "early=tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0000001, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "352/352 [==============================] - 7s 18ms/step - loss: 3.0174 - accuracy: 0.1602 - auc: 0.8314 - val_loss: 2.7276 - val_accuracy: 0.2290 - val_auc: 0.8739\n",
      "Epoch 2/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 2.5589 - accuracy: 0.2656 - auc: 0.8914 - val_loss: 2.3934 - val_accuracy: 0.3004 - val_auc: 0.9073\n",
      "Epoch 3/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 2.2221 - accuracy: 0.3520 - auc: 0.9205 - val_loss: 2.1481 - val_accuracy: 0.3731 - val_auc: 0.9264\n",
      "Epoch 4/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.9716 - accuracy: 0.4178 - auc: 0.9380 - val_loss: 1.9002 - val_accuracy: 0.4380 - val_auc: 0.9432\n",
      "Epoch 5/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.8086 - accuracy: 0.4638 - auc: 0.9473 - val_loss: 1.7952 - val_accuracy: 0.4638 - val_auc: 0.9491\n",
      "Epoch 6/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.6753 - accuracy: 0.5003 - auc: 0.9546 - val_loss: 1.6860 - val_accuracy: 0.5028 - val_auc: 0.9529\n",
      "Epoch 7/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.5758 - accuracy: 0.5273 - auc: 0.9592 - val_loss: 1.6939 - val_accuracy: 0.4941 - val_auc: 0.9513\n",
      "Epoch 8/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.4998 - accuracy: 0.5501 - auc: 0.9628 - val_loss: 1.5268 - val_accuracy: 0.5419 - val_auc: 0.9603\n",
      "Epoch 9/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.4287 - accuracy: 0.5666 - auc: 0.9658 - val_loss: 1.5064 - val_accuracy: 0.5546 - val_auc: 0.9607\n",
      "Epoch 10/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.3607 - accuracy: 0.5876 - auc: 0.9689 - val_loss: 1.4609 - val_accuracy: 0.5613 - val_auc: 0.9627\n",
      "Epoch 11/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.3073 - accuracy: 0.6019 - auc: 0.9706 - val_loss: 1.4496 - val_accuracy: 0.5650 - val_auc: 0.9645\n",
      "Epoch 12/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.2643 - accuracy: 0.6139 - auc: 0.9723 - val_loss: 1.3723 - val_accuracy: 0.5896 - val_auc: 0.9661\n",
      "Epoch 13/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.2223 - accuracy: 0.6252 - auc: 0.9738 - val_loss: 1.3524 - val_accuracy: 0.5982 - val_auc: 0.9670\n",
      "Epoch 14/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.1816 - accuracy: 0.6359 - auc: 0.9755 - val_loss: 1.3396 - val_accuracy: 0.5997 - val_auc: 0.9680\n",
      "Epoch 15/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.1447 - accuracy: 0.6475 - auc: 0.9767 - val_loss: 1.2852 - val_accuracy: 0.6164 - val_auc: 0.9688\n",
      "Epoch 16/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.1063 - accuracy: 0.6579 - auc: 0.9781 - val_loss: 1.2711 - val_accuracy: 0.6173 - val_auc: 0.9700\n",
      "Epoch 17/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.0870 - accuracy: 0.6626 - auc: 0.9787 - val_loss: 1.3023 - val_accuracy: 0.6150 - val_auc: 0.9659\n",
      "Epoch 18/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.0521 - accuracy: 0.6738 - auc: 0.9798 - val_loss: 1.2555 - val_accuracy: 0.6253 - val_auc: 0.9697\n",
      "Epoch 19/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.0241 - accuracy: 0.6826 - auc: 0.9804 - val_loss: 1.2251 - val_accuracy: 0.6318 - val_auc: 0.9701\n",
      "Epoch 20/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 1.0012 - accuracy: 0.6877 - auc: 0.9813 - val_loss: 1.2075 - val_accuracy: 0.6422 - val_auc: 0.9718\n",
      "Epoch 21/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.9733 - accuracy: 0.6970 - auc: 0.9822 - val_loss: 1.1867 - val_accuracy: 0.6523 - val_auc: 0.9711\n",
      "Epoch 22/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.9598 - accuracy: 0.7001 - auc: 0.9825 - val_loss: 1.2020 - val_accuracy: 0.6441 - val_auc: 0.9698\n",
      "Epoch 23/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.9470 - accuracy: 0.7039 - auc: 0.9828 - val_loss: 1.1886 - val_accuracy: 0.6508 - val_auc: 0.9704\n",
      "Epoch 24/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.9180 - accuracy: 0.7131 - auc: 0.9836 - val_loss: 1.1797 - val_accuracy: 0.6584 - val_auc: 0.9701\n",
      "Epoch 25/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.9020 - accuracy: 0.7177 - auc: 0.9840 - val_loss: 1.1545 - val_accuracy: 0.6591 - val_auc: 0.9716\n",
      "Epoch 26/200\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 0.8887 - accuracy: 0.7219 - auc: 0.9844 - val_loss: 1.1833 - val_accuracy: 0.6526 - val_auc: 0.9694\n",
      "Epoch 27/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8690 - accuracy: 0.7276 - auc: 0.9851 - val_loss: 1.1931 - val_accuracy: 0.6478 - val_auc: 0.9692\n",
      "Epoch 28/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8602 - accuracy: 0.7299 - auc: 0.9851 - val_loss: 1.1426 - val_accuracy: 0.6618 - val_auc: 0.9710\n",
      "Epoch 29/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8496 - accuracy: 0.7306 - auc: 0.9857 - val_loss: 1.1323 - val_accuracy: 0.6673 - val_auc: 0.9719\n",
      "Epoch 30/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8316 - accuracy: 0.7383 - auc: 0.9859 - val_loss: 1.1778 - val_accuracy: 0.6552 - val_auc: 0.9691\n",
      "Epoch 31/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8185 - accuracy: 0.7396 - auc: 0.9865 - val_loss: 1.1685 - val_accuracy: 0.6611 - val_auc: 0.9687\n",
      "Epoch 32/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8122 - accuracy: 0.7421 - auc: 0.9867 - val_loss: 1.1563 - val_accuracy: 0.6645 - val_auc: 0.9692\n",
      "Epoch 33/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.8049 - accuracy: 0.7436 - auc: 0.9866 - val_loss: 1.1286 - val_accuracy: 0.6671 - val_auc: 0.9706\n",
      "Epoch 34/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.7827 - accuracy: 0.7506 - auc: 0.9873 - val_loss: 1.1917 - val_accuracy: 0.6547 - val_auc: 0.9665\n",
      "Epoch 35/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.7813 - accuracy: 0.7517 - auc: 0.9873 - val_loss: 1.1862 - val_accuracy: 0.6564 - val_auc: 0.9697\n",
      "Epoch 36/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.7637 - accuracy: 0.7579 - auc: 0.9878 - val_loss: 1.1573 - val_accuracy: 0.6657 - val_auc: 0.9689\n",
      "Epoch 37/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.7529 - accuracy: 0.7592 - auc: 0.9880 - val_loss: 1.1339 - val_accuracy: 0.6756 - val_auc: 0.9692\n",
      "Epoch 38/200\n",
      "352/352 [==============================] - 5s 14ms/step - loss: 0.7468 - accuracy: 0.7608 - auc: 0.9882 - val_loss: 1.1976 - val_accuracy: 0.6586 - val_auc: 0.9656\n",
      "INFO:tensorflow:Assets written to: devnagri-script-detection-test.model\\assets\n"
     ]
    }
   ],
   "source": [
    "# fitting\n",
    "model.fit(X,y,validation_split=0.1,batch_size=200,epochs=200,callbacks=[tensorboard,early])\n",
    "\n",
    "model.save('devnagri-script-detection-test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "def prepare(filepath):\n",
    "    random.seed(1)\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=random.random()*180,\n",
    "        width_shift_range=[-5*random.random(),10*random.random()],\n",
    "        height_shift_range=[-10*random.random(),5*random.random()],\n",
    "        shear_range=10*random.random(),\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        channel_shift_range=random.random())\n",
    "    \n",
    "    img_array=cv2.imread(filepath)\n",
    "    new_array=cv2.resize(img_array,(32,32))\n",
    "    image = img_to_array(new_array)\n",
    "    image = preprocess_input(image)\n",
    "    image = train_datagen.random_transform(image)\n",
    "    image=np.array(image).reshape((-1, 32, 32, 3))\n",
    "    \n",
    "    return image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    ha    [23]\n",
      "2    chhya    [15]\n",
      "3    6    [6]\n",
      "4    sa    [36]\n",
      "5    chha    [14]\n",
      "6    chha    [14]\n",
      "7    da    [16]\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model('devnagri-script-detection-test.model')\n",
    "\n",
    "prediction=[model.predict_classes([prepare('1.jpeg')])]\n",
    "prediction.append(model.predict_classes([prepare('2.jpeg')]))\n",
    "prediction.append(model.predict_classes([prepare('3.jpeg')]))\n",
    "prediction.append(model.predict_classes([prepare('4.jpeg')]))\n",
    "prediction.append(model.predict_classes([prepare('5.jpeg')]))\n",
    "prediction.append(model.predict_classes([prepare('6.jpeg')]))\n",
    "prediction.append(model.predict_classes([prepare('7.jpeg')]))\n",
    "\n",
    "for l in range(len(prediction)):\n",
    "    print((l+1),\"  \",CATEGORIES[int(prediction[l])], \"  \", prediction[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([6], dtype=int64)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
